{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f5e3a24",
   "metadata": {},
   "source": [
    "QUESTION 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a9b035",
   "metadata": {},
   "source": [
    "R-squared represents how much of the variability in the dependent variable is explained by the model. In this case, R² is only 17.6%, which suggests that the model explains a relatively small proportion of the variability in the data. This could happen when:\n",
    "\n",
    "There is significant random variability in the data.\n",
    "\n",
    "Other important predictor variables are missing from the model.\n",
    "\n",
    "\n",
    "P-values for coefficients test whether individual predictors have a statistically significant relationship with the outcome. Even if the model explains a small portion of variability (low R²), individual predictors can still show strong evidence against the null hypothesis (low p-values), meaning they have a statistically significant effect on the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1640577c",
   "metadata": {},
   "source": [
    "QUESTION 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e80053",
   "metadata": {},
   "source": [
    "~From model3 to model4\n",
    "\n",
    "model3: Includes basic predictors (Attack and Defense).\n",
    "\n",
    "These are continuous variables and contribute to understanding their linear relationship with HP.\n",
    "\n",
    "model4: Extends model3 by adding interactions and other predictors (Speed, Legendary, Sp. Def, Sp. Atk).\n",
    "\n",
    "Interactions: Attack * Defense * Speed * Legendary allows the effects of these variables on HP to depend on each other.\n",
    "\n",
    "Reason: To capture potential combined effects of multiple variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d096f055",
   "metadata": {},
   "source": [
    "~ From model4 to model5\n",
    "\n",
    "model5: Adds categorical predictors such as Generation, Type 1, and Type 2.\n",
    "\n",
    "These categorical predictors capture differences in HP across generations and Pokémon types.\n",
    "\n",
    "Dummy Encoding: Allows modeling baseline effects and contrasts between specific groups.\n",
    "\n",
    "Rationale: Improve predictive power by accounting for group-level variations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f044ca",
   "metadata": {},
   "source": [
    "~From model5 to model6\n",
    "\n",
    "model6: Refines model5 by removing less significant predictors and adding specific significant indicators.\n",
    "\n",
    "Adds binary indicator terms like I(Q(\"Type 1\")==\"Normal\") and I(Generation==2).\n",
    "\n",
    "Reason: Focuses on statistically significant predictors to reduce overfitting and improve generalizability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c1096",
   "metadata": {},
   "source": [
    "~model7: Introduces higher-order interactions between continuous predictors (Attack, Speed, Sp. Def, Sp. Atk) while retaining significant categorical indicators.\n",
    "\n",
    "Purpose of interactions: Capture complex relationships that better explain variability in HP.\n",
    "\n",
    "Improved R-squared: Both in-sample and out-of-sample R-squared metrics show better fit and generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c307938e",
   "metadata": {},
   "source": [
    "SUMMARY\n",
    "The models were developed by iteratively adding relevant predictors, interactions, and categorical variables. Each step aimed to balance better fit (R-squared) and generalizability (out-of-sample performance). Centering and scaling improved numerical stability, ensuring reliable coefficient estimates and addressing multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ec7c3b",
   "metadata": {},
   "source": [
    "QUESTION 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad02ca8",
   "metadata": {},
   "source": [
    "1. Complexity and Overfitting\n",
    "Model6: A simpler model that focuses on key predictors and significant indicators.\n",
    "\n",
    "Model7: A more complex model, including higher-order interactions such as Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\").\n",
    "\n",
    "Complexity risk: While model7 performs better in terms of raw out-of-sample R-squared (indicating improved prediction), the p-values of many coefficients in model7 suggest weak evidence for their inclusion.\n",
    "\n",
    "Overfitting risk: Model7 may \"fit\" idiosyncrasies specific to the training data, reducing its reliability when applied to new datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6778eda4",
   "metadata": {},
   "source": [
    "2. Interpretability vs. Performance\n",
    "\n",
    "Interpretability:\n",
    "Simpler models like model6 provide clearer insights into how predictors influence the response variable (HP).\n",
    "\n",
    "Complex interactions (as in model7) make it difficult to interpret specific relationships between predictors and outcomes.\n",
    "\n",
    "When interpretability matters:\n",
    "In practical applications, understanding the model’s structure is critical, especially in scenarios where domain experts or stakeholders need to trust the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a340f0",
   "metadata": {},
   "source": [
    "3. Sequential Prediction (Generalizability Concerns)\n",
    "\n",
    "The illustration of \"sequential prediction\" highlights a practical concern:\n",
    "\n",
    "Real-world application: In practice, new data often arrives sequentially. Models trained on earlier data (e.g., Generations 1-5) are used to predict outcomes for unseen future data (e.g., Generation 6).\n",
    "\n",
    "Findings:\n",
    "When tested on data from unseen generations, model7 shows poorer generalizability than model6, suggesting its performance drops when exposed to new patterns not present in the training data.\n",
    "This reinforces the idea that simpler models can generalize better over time, even if their immediate out-of-sample performance seems slightly worse in idealized testing conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42884ba5",
   "metadata": {},
   "source": [
    "4.The Role of Condition Numbers\n",
    "\n",
    "Multicollinearity concerns:\n",
    "Despite centering and scaling reducing model7's condition number to 15.4 (a safe range), this doesn’t entirely solve interpretability and generalizability issues.\n",
    "Interpretation: Multicollinearity is only one aspect; high condition numbers mainly point to numerical instability, but model complexity can still lead to overfitting even with low multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b35809b",
   "metadata": {},
   "source": [
    "SUMMARY:\n",
    "\n",
    "Parsimony is valuable: A simpler model like model6 strikes a balance between predictive performance and interpretability.\n",
    "Model complexity increases overfitting risk: Especially when coefficients lack strong statistical evidence, as seen in model7.\n",
    "Generalizability > Raw performance: In real-world sequential prediction, simpler models tend to perform more consistently across unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f6cef9",
   "metadata": {},
   "source": [
    "OVERALL SUMMARY:\n",
    "    \n",
    "  \n",
    "\n",
    "1. Model Complexity and Generalizability:\n",
    "   - We discussed how simpler models (e.g., `model6`) focus on key predictors and maintain interpretability, while more complex models (e.g., `model7`) include higher-order interactions, potentially leading to overfitting.\n",
    "   - Complex models might perform better on training data but risk poor generalization to unseen data due to capturing noise rather than true relationships.\n",
    "\n",
    "2. Overfitting and Interpretability:\n",
    "   - Overfitting occurs when a model fits the training data too well, picking up on idiosyncrasies that don’t generalize to new datasets.\n",
    "   - Simpler models are easier to interpret, making them more practical in real-world scenarios where trust and understanding of the model are critical.\n",
    "\n",
    "3. Sequential Prediction and Real-World Application:\n",
    "   - When models are used to predict future data (e.g., new generations of Pokémon), simpler models like `model6` often generalize better compared to more complex models like `model7`.\n",
    "   - We highlighted how training on earlier data (Generations 1-5) and testing on unseen data (Generation 6) exposed generalizability issues, particularly for the more complex `model7`.\n",
    "\n",
    "4. Condition Numbers and Multicollinearity:\n",
    "   - Centering and scaling reduced the condition number in `model7`, indicating less multicollinearity.\n",
    "   - However, low multicollinearity does not fully address overfitting or interpretability issues inherent in complex models.\n",
    "\n",
    "5. Key Takeaways:\n",
    "   - Simpler models offer better generalizability and interpretability.\n",
    "   - Increased model complexity should be justified by significantly improved predictive performance to avoid overfitting.\n",
    "   - In practical applications, parsimony is often preferred, especially when predictive performance between models is comparable. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb93830",
   "metadata": {},
   "source": [
    "ChatGPT link:https://chatgpt.com/share/6736bcff-5f44-8007-8c8d-0a8be8719f01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
